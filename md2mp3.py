#!/usr/bin/env python3
"""
Script pour convertir des fichiers Markdown en MP3.
Utilise Azure Text-to-Speech pour une meilleure qualit√© audio.
G√®re les dialogues avec plusieurs locuteurs et voix vari√©es.

Usage:
    python md2mp3.py texte.md -l fr
    python md2mp3.py texte.md -l all --voix femme
    python md2mp3.py dialogue.md -l fr --voix homme (pour forcer)
"""

import argparse
import os
import re
import random
import time
from pathlib import Path
from dotenv import load_dotenv
import asyncio

try:
    import azure.cognitiveservices.speech as speechsdk
    HAS_AZURE = True
except ImportError:
    HAS_AZURE = False
    print("‚ö†Ô∏è  Azure Speech SDK non install√©. Installez avec: pip install azure-cognitiveservices-speech")

load_dotenv()


class VoiceConfig:
    """Configuration des voix pour chaque langue"""
    
    VOICES = {
        "fr": {
            "female": [
                "fr-FR-DeniseNeural",
                "fr-FR-EloiseNeural",
                "fr-FR-VivienneNeural",
                "fr-FR-BrigitteNeural",
                "fr-FR-CelesteNeural",
                "fr-FR-CoralieNeural",
                "fr-FR-JacquelineNeural",
                "fr-FR-JosephineNeural",
                "fr-FR-YvetteNeural",
                "fr-CH-ArianeNeural",
                "fr-BE-CharlineNeural",
            ],
            "male": [
                "fr-FR-HenriNeural",
                "fr-FR-AlainNeural",
                "fr-FR-ClaudeNeural",
                "fr-FR-JeromeNeural",
                "fr-FR-MauriceNeural",
                "fr-FR-YvesNeural",
                "fr-CH-FabriceNeural",
                "fr-BE-GerardNeural",
            ]
        },
        "all": {
            "female": [
                "de-DE-KatjaNeural",
                "de-DE-AmalaNeural",
                "de-DE-ElkeNeural",
                "de-DE-KlarissaNeural",
                "de-DE-LouisaNeural",
                "de-DE-MajaNeural",
                "de-DE-TanjaNeural",
                "de-CH-LeniNeural",
                "de-AT-IngridNeural",
            ],
            "male": [
                "de-DE-ConradNeural",
                "de-DE-BerndNeural",
                "de-DE-ChristophNeural",
                "de-DE-KasperNeural",
                "de-DE-KillianNeural",
                "de-DE-KlausNeural",
                "de-CH-JanNeural",
                "de-AT-JonasNeural",
            ]
        },
        "eng": {
            "female": [
                "en-GB-LibbyNeural",
                "en-GB-SoniaNeural",
                "en-GB-BellaNeural",
                "en-GB-HollieNeural",
                "en-GB-OliviaNeural",
            ],
            "male": [
                "en-GB-RyanNeural",
                "en-GB-ThomasNeural",
                "en-GB-ElliotNeural",
                "en-GB-EthanNeural",
                "en-GB-OliverNeural",
            ]
        },
        "us": {
            "female": [
                "en-US-AriaNeural",
                "en-US-AvaNeural",
                "en-US-EmmaNeural",
                "en-US-JennyNeural",
                "en-US-MichelleNeural",
                "en-US-MonicaNeural",
                "en-US-AmberNeural",
                "en-US-AnaNeural",
                "en-US-AshleyNeural",
                "en-US-CoraNeural",
                "en-US-ElizabethNeural",
                "en-US-SaraNeural",
            ],
            "male": [
                "en-US-GuyNeural",
                "en-US-BrianNeural",
                "en-US-ChristopherNeural",
                "en-US-EricNeural",
                "en-US-JacobNeural",
                "en-US-JasonNeural",
                "en-US-TonyNeural",
                "en-US-DavisNeural",
            ]
        },
        "esp": {
            "female": [
                "es-ES-ElviraNeural",
                "es-ES-EstrellaNeural",
                "es-ES-Ver√≥nicaNeural",
                "es-ES-AbrilNeural",
                "es-ES-IreneNeural",
                "es-ES-LaiaNeural",
                "es-ES-LiaNeural",
                "es-ES-TrisaNeural",
            ],
            "male": [
                "es-ES-AlvaroNeural",
                "es-ES-ArnauNeural",
                "es-ES-DarioNeural",
                "es-ES-EliasNeural",
                "es-ES-SaulNeural",
                "es-ES-TeoNeural",
            ]
        },
        "hisp": {
            "female": [
                "es-AR-ElenaNeural",
                "es-CO-SalomeNeural",
                "es-MX-BeatrizNeural",
                "es-MX-CarlotaNeural",
                "es-MX-CandelaNeural",
                "es-MX-LarissaNeural",
                "es-MX-MarinaNeural",
                "es-MX-NuriaNeural",
                "es-MX-RenataNeural",
            ],
            "male": [
                "es-AR-TomasNeural",
                "es-MX-JorgeNeural",
                "es-CO-GonzaloNeural",
                "es-MX-CecilioNeural",
                "es-MX-GerardoNeural",
                "es-MX-LibertoNeural",
                "es-MX-LucianoNeural",
                "es-MX-PelayoNeural",
                "es-MX-YagoNeural",
            ]
        },
        "nl": {
            "female": [
                "nl-NL-FennaNeural",
                "nl-NL-ColetteNeural",
                "nl-BE-DenaNeural",
            ],
            "male": [
                "nl-NL-MaartenNeural",
                "nl-NL-CoenNeural",
                "nl-BE-ArnaudNeural",
            ]
        },
        "co": {
            "female": [
                "ko-KR-SunHiNeural",
                "ko-KR-YuJinNeural",
                "ko-KR-SoonBokNeural",
                "ko-KR-JiMinNeural",
            ],
            "male": [
                "ko-KR-InJoonNeural",
                "ko-KR-BongJinNeural",
                "ko-KR-GookMinNeural",
                "ko-KR-HyunsuNeural",
            ]
        },
        "it": {
            "female": [
                "it-IT-ElsaNeural",
                "it-IT-IsabellaNeural",
            ],
            "male": [
                "it-IT-DiegoNeural",
                "it-IT-GiuseppeNeural",
                "it-IT-FabioNeural",
            ]
        }
    }

    # Mapping des pr√©noms vers les IDs Azure complets (tous les langues)
    VOICE_NAMES = {
        # Fran√ßais
        "denise": "fr-FR-DeniseNeural",
        "eloise": "fr-FR-EloiseNeural",
        "vivienne": "fr-FR-VivienneNeural",
        "brigitte": "fr-FR-BrigitteNeural",
        "celeste": "fr-FR-CelesteNeural",
        "coralie": "fr-FR-CoralieNeural",
        "jacqueline": "fr-FR-JacquelineNeural",
        "josephine": "fr-FR-JosephineNeural",
        "yvette": "fr-FR-YvetteNeural",
        "ariane": "fr-CH-ArianeNeural",
        "charline": "fr-BE-CharlineNeural",
        "henri": "fr-FR-HenriNeural",
        "alain": "fr-FR-AlainNeural",
        "claude": "fr-FR-ClaudeNeural",
        "jerome": "fr-FR-JeromeNeural",
        "maurice": "fr-FR-MauriceNeural",
        "yves": "fr-FR-YvesNeural",
        "fabrice": "fr-CH-FabriceNeural",
        "gerard": "fr-BE-GerardNeural",
        
        # Allemand
        "katja": "de-DE-KatjaNeural",
        "amala": "de-DE-AmalaNeural",
        "elke": "de-DE-ElkeNeural",
        "klarissa": "de-DE-KlarissaNeural",
        "louisa": "de-DE-LouisaNeural",
        "maja": "de-DE-MajaNeural",
        "tanja": "de-DE-TanjaNeural",
        "leni": "de-CH-LeniNeural",
        "ingrid": "de-AT-IngridNeural",
        "conrad": "de-DE-ConradNeural",
        "bernd": "de-DE-BerndNeural",
        "christoph": "de-DE-ChristophNeural",
        "kasper": "de-DE-KasperNeural",
        "killian": "de-DE-KillianNeural",
        "klaus": "de-DE-KlausNeural",
        "jan": "de-CH-JanNeural",
        "jonas": "de-AT-JonasNeural",
        
        # Anglais UK
        "libby": "en-GB-LibbyNeural",
        "maisie": "en-GB-MaisieNeural",
        "sonia": "en-GB-SoniaNeural",
        "bella": "en-GB-BellaNeural",
        "hollie": "en-GB-HollieNeural",
        "olivia": "en-GB-OliviaNeural",
        "ryan": "en-GB-RyanNeural",
        "thomas": "en-GB-ThomasNeural",
        "alfie": "en-GB-AlfieNeural",
        "elliot": "en-GB-ElliotNeural",
        "ethan": "en-GB-EthanNeural",
        "noah": "en-GB-NoahNeural",
        "oliver": "en-GB-OliverNeural",
        
        # Anglais US
        "aria": "en-US-AriaNeural",
        "ava": "en-US-AvaNeural",
        "emma": "en-US-EmmaNeural",
        "jenny": "en-US-JennyNeural",
        "michelle": "en-US-MichelleNeural",
        "monica": "en-US-MonicaNeural",
        "amber": "en-US-AmberNeural",
        "ana": "en-US-AnaNeural",
        "ashley": "en-US-AshleyNeural",
        "cora": "en-US-CoraNeural",
        "elizabeth": "en-US-ElizabethNeural",
        "sara": "en-US-SaraNeural",
        "guy": "en-US-GuyNeural",
        "brian": "en-US-BrianNeural",
        "christopher": "en-US-ChristopherNeural",
        "eric": "en-US-EricNeural",
        "jacob": "en-US-JacobNeural",
        "jason": "en-US-JasonNeural",
        "tony": "en-US-TonyNeural",
        "davis": "en-US-DavisNeural",
        
        # Espagnol Espagne
        "elvira": "es-ES-ElviraNeural",
        "estrella": "es-ES-EstrellaNeural",
        "veronica": "es-ES-Ver√≥nicaNeural",
        "abril": "es-ES-AbrilNeural",
        "irene": "es-ES-IreneNeural",
        "laia": "es-ES-LaiaNeural",
        "lia": "es-ES-LiaNeural",
        "trisa": "es-ES-TrisaNeural",
        "alvaro": "es-ES-AlvaroNeural",
        "arnau": "es-ES-ArnauNeural",
        "dario": "es-ES-DarioNeural",
        "elias": "es-ES-EliasNeural",
        "nil": "es-ES-NilNeural",
        "saul": "es-ES-SaulNeural",
        "teo": "es-ES-TeoNeural",
        
        # Espagnol Am√©rique latine
        "elena": "es-AR-ElenaNeural",
        "marta": "es-MX-MartaNeural",
        "salome": "es-CO-SalomeNeural",
        "beatriz": "es-MX-BeatrizNeural",
        "carlota": "es-MX-CarlotaNeural",
        "candela": "es-MX-CandelaNeural",
        "larissa": "es-MX-LarissaNeural",
        "marina": "es-MX-MarinaNeural",
        "nuria": "es-MX-NuriaNeural",
        "renata": "es-MX-RenataNeural",
        "tomas": "es-AR-TomasNeural",
        "jorge": "es-MX-JorgeNeural",
        "gonzalo": "es-CO-GonzaloNeural",
        "cecilio": "es-MX-CecilioNeural",
        "gerardo": "es-MX-GerardoNeural",
        "liberto": "es-MX-LibertoNeural",
        "luciano": "es-MX-LucianoNeural",
        "pelayo": "es-MX-PelayoNeural",
        "yago": "es-MX-YagoNeural",
        
        # N√©erlandais
        "fenna": "nl-NL-FennaNeural",
        "colette": "nl-NL-ColetteNeural",
        "dena": "nl-BE-DenaNeural",
        "maarten": "nl-NL-MaartenNeural",
        "coen": "nl-NL-CoenNeural",
        "arnaud": "nl-BE-ArnaudNeural",
        
        # Cor√©en
        "sunhi": "ko-KR-SunHiNeural",
        "yujin": "ko-KR-YuJinNeural",
        "hyunju": "ko-KR-HyunjuNeural",
        "soonbok": "ko-KR-SoonBokNeural",
        "jimin": "ko-KR-JiMinNeural",
        "injoon": "ko-KR-InJoonNeural",
        "bongjin": "ko-KR-BongJinNeural",
        "gookmin": "ko-KR-GookMinNeural",
        "hyunsu": "ko-KR-HyunsuNeural",
        
        # Italien
        "elsa": "it-IT-ElsaNeural",
        "isabella": "it-IT-IsabellaNeural",
        "diego": "it-IT-DiegoNeural",
        "giuseppe": "it-IT-GiuseppeNeural",
        "lucio": "it-IT-LucioNeural",
        "fabio": "it-IT-FabioNeural",
    }

    @classmethod
    def get_voice_by_name(cls, voice_name):
        """Retourne l'ID Azure complet √† partir d'un pr√©nom"""
        voice_name_lower = voice_name.lower()
        if voice_name_lower in cls.VOICE_NAMES:
            return cls.VOICE_NAMES[voice_name_lower]
        raise ValueError(f"Voix non trouv√©e: {voice_name}. Utilisez --help pour voir les voix disponibles.")

    @classmethod
    def get_random_voice(cls, langue, gender=None):
        """Retourne une voix al√©atoire pour une langue et genre donn√©s"""
        if langue not in cls.VOICES:
            raise ValueError(f"Langue non support√©e: {langue}")
        
        if gender is None:
            gender = random.choice(["female", "male"])
        
        if gender not in cls.VOICES[langue]:
            gender = list(cls.VOICES[langue].keys())[0]
        
        voices = cls.VOICES[langue][gender]
        return random.choice(voices)

    @classmethod
    def get_voice(cls, langue, gender=None, voice_name=None):
        """Retourne une voix pour une langue et genre donn√©s, ou une voix sp√©cifique par nom"""
        # Priorit√© au nom de voix sp√©cifique
        if voice_name:
            return cls.get_voice_by_name(voice_name)
        # Sinon, s√©lection par genre
        if gender:
            return cls.get_random_voice(langue, gender)
        # Par d√©faut, al√©atoire
        return cls.get_random_voice(langue)


class MarkdownCleaner:
    """Nettoie le texte Markdown pour la lecture TTS"""
    
    # Traductions des √©l√©ments math√©matiques par langue
    MATH_TRANSLATIONS = {
        "fr": {
            "^2": " au carr√©",
            "^3": " au cube",
            "^": " exposant ",
            "\\sqrt": "racine",
            "=": " √©gal ",
            "+": " plus ",
            "-": " moins ",
            "*": " fois ",
            "/": " divis√© par ",
        },
        "eng": {
            "^2": " squared",
            "^3": " cubed",
            "^": " to the power of ",
            "\\sqrt": "square root",
            "=": " equals ",
            "+": " plus ",
            "-": " minus ",
            "*": " times ",
            "/": " divided by ",
        },
        "us": {
            "^2": " squared",
            "^3": " cubed",
            "^": " to the power of ",
            "\\sqrt": "square root",
            "=": " equals ",
            "+": " plus ",
            "-": " minus ",
            "*": " times ",
            "/": " divided by ",
        },
        "all": {  # Allemand
            "^2": " zum Quadrat",
            "^3": " zum Kubik",
            "^": " hoch ",
            "\\sqrt": "Quadratwurzel",
            "=": " gleich ",
            "+": " plus ",
            "-": " minus ",
            "*": " mal ",
            "/": " geteilt durch ",
        },
        "esp": {  # Espagnol
            "^2": " al cuadrado",
            "^3": " al cubo",
            "^": " a la potencia ",
            "\\sqrt": "ra√≠z cuadrada",
            "=": " igual ",
            "+": " m√°s ",
            "-": " menos ",
            "*": " por ",
            "/": " dividido por ",
        },
        "hisp": {  # Hispanique (m√™me que esp)
            "^2": " al cuadrado",
            "^3": " al cubo",
            "^": " a la potencia ",
            "\\sqrt": "ra√≠z cuadrada",
            "=": " igual ",
            "+": " m√°s ",
            "-": " menos ",
            "*": " por ",
            "/": " dividido por ",
        },
        "nl": {  # N√©erlandais
            "^2": " kwadraat",
            "^3": " kubiek",
            "^": " tot de macht ",
            "\\sqrt": "vierkantswortel",
            "=": " gelijk ",
            "+": " plus ",
            "-": " min ",
            "*": " keer ",
            "/": " gedeeld door ",
        },
        "co": {  # Cor√©en
            "^2": " Ï†úÍ≥±",
            "^3": " ÏÑ∏Ï†úÍ≥±",
            "^": " Ïùò Í±∞Îì≠Ï†úÍ≥± ",
            "\\sqrt": "Ï†úÍ≥±Í∑º",
            "=": " Í∞ôÏùå ",
            "+": " ÎçîÌïòÍ∏∞ ",
            "-": " ÎπºÍ∏∞ ",
            "*": " Í≥±ÌïòÍ∏∞ ",
            "/": " ÎÇòÎàÑÍ∏∞ ",
        }
    }

    @staticmethod
    def markdown_to_ssml(text):
        """
        Convertit les marqueurs Markdown en balises SSML.
        - *mot* ‚Üí <emphasis> + <prosody pitch="+10%"> (emphasis mod√©r√©e visible)
        - **mot** ‚Üí <emphasis> + <prosody pitch="+20%" rate="slow"> (emphasis forte tr√®s marqu√©e)
        - [p] ‚Üí <break time="250ms"/>
        - [p:300] ‚Üí <break time="300ms"/>
        
        Note: Combinaison emphasis + prosody pour forcer Azure √† appliquer l'emphasis
        """
        # Convertir **mot** en emphasis forte TR√àS marqu√©e
        # Combiner emphasis, pitch √©lev√©, ralentissement, et volume fort
        text = re.sub(
            r'\*\*([^*]+)\*\*',
            r'<emphasis level="strong"><prosody pitch="+20%" rate="slow" volume="x-loud">\1</prosody></emphasis>',
            text
        )
        
        # Convertir *mot* en emphasis mod√©r√©e marqu√©e
        text = re.sub(
            r'\*([^*]+)\*',
            r'<emphasis level="moderate"><prosody pitch="+10%" volume="loud">\1</prosody></emphasis>',
            text
        )
        
        # Convertir [p:XXX] avec dur√©e custom
        text = re.sub(r'\[p:(\d+)\]', r'<break time="\1ms"/>', text)
        
        # Convertir [p] en pause par d√©faut (250ms)
        text = re.sub(r'\[p\]', '<break time="250ms"/>', text)
        
        return text
    
    @staticmethod
    def clean_text(text, langue="fr", enable_ssml=False):
        """Supprime la syntaxe Markdown et les √©l√©ments non lus
        
        Args:
            text: Texte Markdown √† nettoyer
            langue: Langue pour la conversion d'√©quations
            enable_ssml: Si True, convertit *mot* et [p] en SSML; si False, supprime ces marqueurs
        """
        
        # Supprimer le frontmatter YAML
        text = re.sub(r'^---.*?---\n', '', text, flags=re.DOTALL)

        # Supprimer le bloc vocabulaire complet (garde uniquement le texte principal)
        text = MarkdownCleaner._remove_vocabulary_section(text)

        # Supprimer un √©ventuel titre "Text"/"Texte"/"Texto" isol√© en t√™te de fichier
        text = re.sub(r'^\s*(?:#{1,6}\s*)?(?:text|texte|texto|tekst)\s*\n+', '', text, flags=re.IGNORECASE)
        
        # Supprimer les titres Markdown
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)
        
        # Par d√©faut (SSML d√©sactiv√©), supprimer les marqueurs [p], [p:XXX] et les emphasis * **
        if not enable_ssml:
            text = re.sub(r'\[p(?::\d+)?\]', '', text)
            text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
            text = re.sub(r'\*([^*]+)\*', r'\1', text)
        else:
            # SSML activ√©: convertir les marqueurs markdown vers SSML
            text = MarkdownCleaner.markdown_to_ssml(text)
        
        # Supprimer les liens Markdown (mais garder le texte)
        text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)
        
        # Supprimer le gras et l'italique des underscores (__ et _)
        text = re.sub(r'__([^_]+)__', r'\1', text)
        text = re.sub(r'_([^_]+)_', r'\1', text)
        
        # Supprimer les listes Markdown
        text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
        
        # Convertir les √©quations math√©matiques en texte lisible
        text = MarkdownCleaner._convert_equations(text, langue)
        
        # Supprimer les blocs de code
        text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)
        text = re.sub(r'`([^`]+)`', r'\1', text)
        
        # Supprimer les balises HTML en fonction du mode SSML
        if enable_ssml:
            # SSML activ√©: ne pas supprimer les balises pour √©viter de casser la
            # structure des balises SSML ins√©r√©es (emphasis/prosody/break).
            # Les autres nettoyages en amont ont d√©j√† retir√© le Markdown.
            pass
        else:
            # SSML d√©sactiv√©: supprimer toutes les balises
            text = re.sub(r'<[^>]+>', '', text)
        
        # Nettoyer les espaces superflus
        text = re.sub(r'\n\n+', '\n\n', text)
        text = re.sub(r' +', ' ', text)
        
        return text.strip()

    @staticmethod
    def _remove_vocabulary_section(text):
        """Supprime la section vocabulaire (quel que soit le heading)"""
        vocab_headings = [
            "vocabulaire", "vocabulary", "vocabulario", "wortschatz", "glossary", "vocabul√°rio", "vocabolario"
        ]
        pattern = r'^\s*(?:#{1,6}\s*)?(?:' + '|'.join(vocab_headings) + r')\s*$'
        match = re.search(pattern, text, flags=re.IGNORECASE | re.MULTILINE)
        if match:
            return text[:match.start()].rstrip()
        return text

    @staticmethod
    def _convert_equations(text, langue="fr"):
        """Convertit les √©quations math√©matiques en texte lisible selon la langue"""
        
        # S√©lectionner la traduction appropri√©e
        translations = MarkdownCleaner.MATH_TRANSLATIONS.get(langue, MarkdownCleaner.MATH_TRANSLATIONS["fr"])
        
        # √âquations inline avec $...$
        def convert_inline_eq(match):
            eq = match.group(1)
            
            # Appliquer les traductions dans l'ordre appropri√©
            # D'abord les puissances sp√©ciales (^2, ^3) avant la puissance g√©n√©rale (^)
            eq = eq.replace('^2', translations["^2"])
            eq = eq.replace('^3', translations["^3"])
            eq = eq.replace('^', translations["^"])
            
            # Puis les autres √©l√©ments
            eq = eq.replace('\\sqrt', translations["\\sqrt"])
            eq = eq.replace('\\', '')
            eq = eq.replace('{', '(')
            eq = eq.replace('}', ')')
            eq = eq.replace('=', translations["="])
            eq = eq.replace('+', translations["+"])
            eq = eq.replace('-', translations["-"])
            eq = eq.replace('*', translations["*"])
            eq = eq.replace('/', translations["/"])
            
            return f" {eq} "
        
        text = re.sub(r'\$([^$]+)\$', convert_inline_eq, text)
        
        # √âquations bloc avec $$...$$
        text = re.sub(r'\$\$([^$]+)\$\$', convert_inline_eq, text, flags=re.DOTALL)
        
        return text

    @staticmethod
    def detect_dialogue(text):
        """D√©tecte si le texte contient un dialogue et retourne les locuteurs"""
        
        # Motifs courants pour les dialogues
        patterns = [
            r'^[A-Z][^:]+:\s+(.+)$',  # Nom: texte
            r'^‚Äî\s+(.+)$',             # ‚Äî texte
            r'^\*\*[A-Z][^*]+\*\*:\s+(.+)$',  # **Nom**: texte
        ]
        
        dialogue_lines = []
        for line in text.split('\n'):
            for pattern in patterns:
                if re.match(pattern, line):
                    dialogue_lines.append(line)
                    break
        
        # Si plus de 30% du texte est du dialogue, c'est un dialogue
        return len(dialogue_lines) > len(text.split('\n')) * 0.3, dialogue_lines

    @staticmethod
    def parse_dialogue_line(line):
        """Extrait le locuteur et le texte d'une ligne de dialogue"""
        
        # Motif: Nom: texte
        match = re.match(r'^([A-Z][^:]+):\s+(.+)$', line)
        if match:
            return match.group(1).strip(), match.group(2).strip()
        
        # Motif: ‚Äî texte
        match = re.match(r'^‚Äî\s+(.+)$', line)
        if match:
            return "Narrateur", match.group(1).strip()
        
        # Motif: **Nom**: texte
        match = re.match(r'^\*\*([^*]+)\*\*:\s+(.+)$', line)
        if match:
            return match.group(1).strip(), match.group(2).strip()
        
        return None, line


class DialogueVoiceAssigner:
    """Assigne des voix diff√©rentes aux personnages d'un dialogue"""

    def __init__(self, langue, forced_gender=None):
        self.langue = langue
        self.forced_gender = forced_gender
        self.speaker_voices = {}
        self.used_voices = set()
        self.genders = {}

    def assign_gender_to_speaker(self, speaker_name):
        """Assigne un genre au locuteur selon son nom"""
        if speaker_name in self.genders:
            return self.genders[speaker_name]
        
        # Noms fran√ßais f√©minins communs
        female_names_fr = ['Marie', 'Sophie', 'Emma', 'Anne', 'Claire', '√âlise', 'Jeanne', 'Isabelle', 'Catherine']
        male_names_fr = ['Jean', 'Pierre', 'Paul', 'Marc', 'Andr√©', 'Fran√ßois', 'Philippe', 'Michel', 'Joseph']
        
        # Noms allemands f√©minins communs
        female_names_de = ['Maria', 'Anna', 'Greta', 'Gisela', 'Petra', 'Claudia', 'Eva', 'Monika', 'Renate']
        male_names_de = ['Hans', 'Klaus', 'Werner', 'Franz', 'Josef', 'Friedrich', 'Wilhelm', 'Johann', 'Heinrich']
        
        all_female = female_names_fr + female_names_de
        all_male = male_names_fr + male_names_de
        
        if speaker_name in all_female:
            gender = "female"
        elif speaker_name in all_male:
            gender = "male"
        else:
            # Choix al√©atoire si nom inconnu
            gender = random.choice(["female", "male"])
        
        self.genders[speaker_name] = gender
        return gender

    def get_voice_for_speaker(self, speaker_name):
        """Retourne une voix unique pour ce locuteur"""
        
        if speaker_name in self.speaker_voices:
            return self.speaker_voices[speaker_name]
        
        # D√©terminer le genre du locuteur
        if self.forced_gender:
            gender = self.forced_gender
        else:
            gender = self.assign_gender_to_speaker(speaker_name)
        
        # Obtenir une voix unique (pas encore utilis√©e)
        voices = VoiceConfig.VOICES[self.langue][gender]
        available_voices = [v for v in voices if v not in self.used_voices]
        
        if not available_voices:
            # R√©initialiser si plus de voix disponibles
            self.used_voices.clear()
            available_voices = voices
        
        voice = random.choice(available_voices)
        self.used_voices.add(voice)
        self.speaker_voices[speaker_name] = voice
        
        return voice


class EdgeTTSGenerator:
    """G√©n√®re l'audio avec Edge TTS (g√©n√®re MP3 directement, sans ffmpeg)"""
    
    # Mapping des langues vers les voix Edge TTS
    EDGE_VOICES = {
        "fr": {
            "female": "fr-FR-DeniseNeural",
            "male": "fr-FR-HenriNeural"
        },
        "eng": {
            "female": "en-GB-LibbyNeural",
            "male": "en-GB-RyanNeural"
        },
        "us": {
            "female": "en-US-AriaNeural",
            "male": "en-US-GuyNeural"
        },
        "esp": {
            "female": "es-ES-ElviraNeural",
            "male": "es-ES-AlvaroNeural"
        },
        "hisp": {
            "female": "es-MX-MartaNeural",
            "male": "es-MX-JorgeNeural"
        },
        "nl": {
            "female": "nl-NL-FennaNeural",
            "male": "nl-NL-CoenNeural"
        },
        "co": {
            "female": "ko-KR-SunHiNeural",
            "male": "ko-KR-InJoonNeural"
        }
    }
    
    def __init__(self, langue="fr", gender=None):
        self.langue = langue
        # Convertir gender de fran√ßais vers anglais
        if gender == "femme":
            self.gender = "female"
        elif gender == "homme":
            self.gender = "male"
        else:
            self.gender = gender
    
    async def generate_audio_from_text_async(self, text, output_file, voice=None):
        """G√©n√®re un fichier MP3 √† partir du texte (async)"""
        try:
            import edge_tts
        except ImportError:
            return False, "‚ùå edge-tts non install√©"
        
        # Valider le texte
        if not text or not text.strip():
            return False, "‚ùå Texte vide"
        
        if voice is None:
            # Choisir une voix par d√©faut
            gender = self.gender or "female"
            voice = self.EDGE_VOICES.get(self.langue, {}).get(gender, "fr-FR-DeniseNeural")
        
        try:
            # Limiter la longueur du texte (Edge TTS a des limites)
            max_length = 10000
            if len(text) > max_length:
                text = text[:max_length]
                print(f"‚ö†Ô∏è  Texte tronqu√© √† {max_length} caract√®res pour Edge TTS")
            
            comm = edge_tts.Communicate(text=text, voice=voice)
            await asyncio.wait_for(comm.save(output_file), timeout=30.0)
            
            # V√©rifier que le fichier a √©t√© cr√©√© et n'est pas vide
            from pathlib import Path
            if not Path(output_file).exists() or Path(output_file).stat().st_size == 0:
                return False, f"‚ùå Edge TTS n'a pas g√©n√©r√© de fichier audio valide"
            
            return True, f"‚úÖ Audio g√©n√©r√© (Edge TTS): {voice}"
        except asyncio.TimeoutError:
            return False, f"‚ùå Timeout Edge TTS (30s d√©pass√©)"
        except Exception as e:
            error_msg = str(e)
            if "No audio" in error_msg:
                return False, f"‚ùå Edge TTS ne peut pas synth√©tiser ce texte. V√©rifiez la langue '{self.langue}' et la voix '{voice}'"
            return False, f"‚ùå Erreur Edge TTS: {error_msg}"
    
    def generate_audio_from_text(self, text, output_file, voice=None):
        """G√©n√®re un fichier MP3 √† partir du texte (wrapper sync)"""
        try:
            # Si le texte est tr√®s long, le diviser en chunks
            if len(text) > 2000:
                return self._generate_audio_chunked(text, output_file, voice)
            
            return asyncio.run(self.generate_audio_from_text_async(text, output_file, voice))
        except Exception as e:
            return False, f"‚ùå Erreur lors de l'ex√©cution async Edge TTS: {str(e)}"
    
    def _generate_audio_chunked(self, text, output_file, voice=None):
        """G√©n√®re l'audio Edge TTS en divisant le texte en chunks"""
        from pathlib import Path
        
        print(f"üì¶ Texte long ({len(text)} chars), division en chunks...")
        
        # Diviser par paragraphes
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        chunk_files = []
        temp_dir = Path(output_file).parent
        
        for i, paragraph in enumerate(paragraphs):
            chunk_file = temp_dir / f"_edge_chunk_{i}.mp3"
            chunk_files.append(chunk_file)
            
            print(f"üìù Chunk {i+1}/{len(paragraphs)}: {len(paragraph)} chars...")
            
            # G√©n√©rer le chunk
            success, msg = asyncio.run(self.generate_audio_from_text_async(paragraph, str(chunk_file), voice))
            if not success:
                # Nettoyer les chunks partiels
                for f in chunk_files:
                    f.unlink(missing_ok=True)
                return False, msg
        
        # Combiner les fichiers MP3 avec ffmpeg
        try:
            import subprocess
            concat_file = temp_dir / "concat.txt"
            with open(concat_file, 'w') as f:
                for chunk in chunk_files:
                    f.write(f"file '{chunk.absolute()}'\n")
            
            cmd = [
                'ffmpeg', '-f', 'concat', '-safe', '0',
                '-i', str(concat_file.absolute()),
                '-c', 'copy', '-y', output_file
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            # Nettoyer les fichiers temporaires
            concat_file.unlink(missing_ok=True)
            for chunk in chunk_files:
                chunk.unlink(missing_ok=True)
            
            if result.returncode == 0:
                return True, f"‚úÖ Audio g√©n√©r√© (en chunks): {voice or 'Edge TTS'}"
            else:
                return False, f"‚ùå Erreur ffmpeg: {result.stderr}"
        
        except FileNotFoundError:
            # ffmpeg non disponible, retourner simplement le premier chunk
            print("‚ö†Ô∏è  ffmpeg non disponible, utilisation du premier chunk")
            try:
                chunk_files[0].rename(output_file)
                for chunk in chunk_files[1:]:
                    chunk.unlink(missing_ok=True)
                return True, f"‚úÖ Audio g√©n√©r√© (chunk 1): {voice or 'Edge TTS'}"
            except Exception as e:
                return False, f"‚ùå Erreur: {str(e)}"
        except Exception as e:
            # Nettoyer en cas d'erreur
            for chunk in chunk_files:
                chunk.unlink(missing_ok=True)
            return False, f"‚ùå Erreur lors de la combinaison: {str(e)}"
    
    async def generate_dialogue_audio_async(self, dialogue_segments, output_file):
        """G√©n√®re un MP3 √† partir de segments de dialogue (async)"""
        try:
            import edge_tts
        except ImportError:
            return False, "‚ùå edge-tts non install√©"
        
        if not dialogue_segments:
            return False, "‚ùå Aucun segment de dialogue"
        
        # Choisir des voix al√©atoires pour chaque locuteur
        speakers_voices = {}
        available_voices = list(self.EDGE_VOICES.get(self.langue, {"female": "fr-FR-DeniseNeural", "male": "fr-FR-HenriNeural"}).values())
        
        # G√©n√©rer un fichier MP3 pour chaque segment
        segment_files = []
        
        for i, (speaker, text) in enumerate(dialogue_segments):
            if not text or not text.strip():
                continue
                
            # Obtenir ou assigner une voix pour ce locuteur
            if speaker not in speakers_voices:
                speakers_voices[speaker] = random.choice(available_voices)
            
            edge_voice = speakers_voices[speaker]
            
            # G√©n√©rer l'audio pour cette partie
            segment_file = f"/tmp/segment_{i}_{len(dialogue_segments)}.mp3"
            
            try:
                comm = edge_tts.Communicate(text=text, voice=edge_voice)
                await asyncio.wait_for(comm.save(segment_file), timeout=30.0)
                
                # V√©rifier que le fichier a √©t√© cr√©√©
                from pathlib import Path
                if Path(segment_file).exists() and Path(segment_file).stat().st_size > 0:
                    segment_files.append(segment_file)
                else:
                    return False, f"‚ùå Segment {i} n'a pas g√©n√©r√© de fichier valide"
                    
            except asyncio.TimeoutError:
                return False, f"‚ùå Timeout Edge TTS sur le segment {i}"
            except Exception as e:
                error_msg = str(e)
                if "No audio" in error_msg:
                    return False, f"‚ùå Edge TTS ne peut pas synth√©tiser le segment {i}"
                return False, f"‚ùå Erreur sur le segment {i}: {error_msg}"
        
        # Fusionner les MP3 (simple concat√©nation)
        if segment_files:
            try:
                # Concat√©nation simple des MP3
                with open(output_file, 'wb') as outfile:
                    for seg_file in segment_files:
                        with open(seg_file, 'rb') as infile:
                            outfile.write(infile.read())
                
                # Nettoyer les segments temporaires
                import os
                for seg_file in segment_files:
                    try:
                        os.remove(seg_file)
                    except:
                        pass
                
                return True, f"‚úÖ Dialogue MP3 g√©n√©r√© (Edge TTS): {output_file}"
            except Exception as e:
                return False, f"‚ùå Erreur lors de la fusion: {str(e)}"
        
        return False, "‚ùå Aucun segment g√©n√©r√©"
    
    def generate_dialogue_audio(self, dialogue_segments, output_file, output_format='mp3'):
        """G√©n√®re un MP3 √† partir de segments de dialogue (wrapper sync)"""
        try:
            return asyncio.run(self.generate_dialogue_audio_async(dialogue_segments, output_file))
        except Exception as e:
            return False, f"‚ùå Erreur lors de l'ex√©cution async dialogue Edge TTS: {str(e)}"


class AzureTTSGenerator:
    """G√©n√®re l'audio avec Azure Text-to-Speech"""

    def __init__(self, langue="fr", gender=None, voice_name=None, speed=1.0):
        if not HAS_AZURE:
            raise RuntimeError("Azure Speech SDK non install√©")
        
        self.langue = langue
        
        # Convertir gender de fran√ßais vers anglais (femme ‚Üí female, homme ‚Üí male)
        if gender == "femme":
            self.gender = "female"
        elif gender == "homme":
            self.gender = "male"
        else:
            self.gender = gender
        
        self.voice_name = voice_name  # Nom sp√©cifique de voix (prioritaire sur gender)
        self.speed = speed  # Vitesse de lecture (0.6 √† 1.0)
        self.api_key = os.getenv("AZURE_SPEECH_KEY")
        self.region = os.getenv("AZURE_SPEECH_REGION", "eastus")
        
        if not self.api_key:
            raise ValueError("Variable AZURE_SPEECH_KEY non trouv√©e dans .env")
        
        # Initialiser le client Azure
        self.speech_config = speechsdk.SpeechConfig(
            subscription=self.api_key,
            region=self.region
        )
        
        # Configurer le format de sortie en MP3 directement
        self.speech_config.set_speech_synthesis_output_format(
            speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3
        )

    def generate_audio_from_text(self, text, output_file, voice=None):
        """G√©n√®re un fichier MP3 √† partir du texte"""
        
        if voice is None:
            # Utiliser voice_name si sp√©cifi√©, sinon gender, sinon al√©atoire
            voice = VoiceConfig.get_voice(self.langue, self.gender, self.voice_name)
        
        self.speech_config.speech_synthesis_voice_name = voice
        
        # Configurer les timeouts pour Azure (en millisecondes)
        # Augmenter pour les textes longs ou connexions lentes
        self.speech_config.set_property(
            speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs,
            "120000"  # 120 secondes pour l'attente initiale
        )
        self.speech_config.set_property(
            speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs,
            "120000"  # 120 secondes pour la fin du silence
        )
        
        # Si le texte est tr√®s long (>2000 chars), le diviser en chunks
        if len(text) > 2000:
            return self._generate_audio_chunked(text, output_file, voice)
        else:
            return self._synthesize_to_file(text, output_file, voice)
    
    def _synthesize_to_file(self, text, output_file, voice):
        """Synth√©tise le texte en fichier MP3 (sans chunking)"""
        # Configurer la sortie audio
        audio_config = speechsdk.audio.AudioOutputConfig(filename=output_file)
        
        # Cr√©er le synth√©tiseur
        synthesizer = speechsdk.SpeechSynthesizer(
            speech_config=self.speech_config,
            audio_config=audio_config
        )
        
        # Cr√©er le SSML avec contr√¥le de vitesse
        # Convertir speed (0.6-1.0) en pourcentage pour SSML (-40% √† 0%)
        speed_percent = int((self.speed - 1.0) * 100)
        speed_str = f"{speed_percent:+d}%" if speed_percent != 0 else "0%"
        
        # Si le texte contient d√©j√† des balises SSML (prosody, break, etc.),
        # on l'ins√®re directement sans wrapper prosody rate pour √©viter les conflits
        # Sinon, on wrappe avec prosody rate pour contr√¥ler la vitesse
        if '<prosody' in text or '<break' in text or '<emphasis' in text:
            # Texte avec SSML: on applique le rate globalement AUTOUR des balises existantes
            # Note: on garde le rate dans le wrapper principal, les balises internes ont priorit√©
            ssml = f'''<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="{voice[:5]}">
                <voice name="{voice}">
                    <prosody rate="{speed_str}">
                        {text}
                    </prosody>
                </voice>
            </speak>'''
        else:
            # Texte sans SSML: wrapper standard
            ssml = f'''<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="{voice[:5]}">
                <voice name="{voice}">
                    <prosody rate="{speed_str}">
                        {text}
                    </prosody>
                </voice>
            </speak>'''
        
        # G√©n√©rer l'audio avec SSML - 2 tentatives avec pause tr√®s longue pour laisser retomber les 429
        max_retries = 2
        retry_delay = 60  # 1 minute entre tentatives si 429/timeout
        for attempt in range(max_retries):
            try:
                result = synthesizer.speak_ssml_async(ssml).get()
                
                if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                    return True, f"‚úÖ Audio g√©n√©r√©: {voice}"
                elif result.reason == speechsdk.ResultReason.Canceled:
                    cancellation = result.cancellation_details
                    error_msg = f"Annul√©: {cancellation.reason}"
                    if cancellation.error_details:
                        error_msg += f" - {cancellation.error_details}"
                    
                    # Retry pour 429 ou timeout - pause longue
                    if ("Timeout" in error_msg or "429" in error_msg or "Too many requests" in error_msg) and attempt < max_retries - 1:
                        error_type = 'Rate limit' if ('429' in error_msg or 'Too many' in error_msg) else 'Timeout'
                        print(f"‚è±Ô∏è  {error_type} Azure, pause {retry_delay}s avant nouvelle tentative...")
                        time.sleep(retry_delay)
                        continue
                    
                    return False, f"‚ùå Erreur TTS: {error_msg}"
                else:
                    return False, f"‚ùå Erreur TTS: Raison inconnue - {result.reason}"
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"‚è±Ô∏è  Exception, pause {retry_delay}s avant nouvelle tentative: {str(e)[:100]}")
                    time.sleep(retry_delay)
                    continue
                return False, f"‚ùå Erreur TTS: {str(e)}"
        
        return False, "‚ùå Erreur TTS: Max retries atteint"
    
    def _generate_audio_chunked(self, text, output_file, voice):
        """G√©n√®re l'audio en divisant le texte en chunks
        
        Divise par paragraphes et g√©n√®re les audios s√©par√©ment,
        puis les combine en un seul fichier.
        """
        import subprocess
        from pathlib import Path
        
        print(f"üì¶ Texte long ({len(text)} chars), division en chunks...")
        
        # Diviser par paragraphes
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        chunk_files = []
        temp_dir = Path(output_file).parent
        
        for i, paragraph in enumerate(paragraphs):
            chunk_file = temp_dir / f"_chunk_{i}.mp3"
            chunk_files.append(chunk_file)
            
            print(f"üìù Chunk {i+1}/{len(paragraphs)}: {len(paragraph)} chars...")
            
            # G√©n√©rer le chunk
            success, msg = self._synthesize_to_file(paragraph, str(chunk_file), voice)
            if not success:
                # Nettoyer les chunks partiels
                for f in chunk_files:
                    f.unlink(missing_ok=True)
                return False, msg
        
        # Combiner les fichiers MP3 avec ffmpeg (ou alternative pydub)
        try:
            concat_file = temp_dir / "concat.txt"
            with open(concat_file, 'w') as f:
                for chunk in chunk_files:
                    f.write(f"file '{chunk.absolute()}'\n")
            
            cmd = [
                'ffmpeg', '-f', 'concat', '-safe', '0',
                '-i', str(concat_file.absolute()),
                '-c', 'copy', '-y', output_file
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            # Nettoyer le fichier concat
            concat_file.unlink(missing_ok=True)
            
            # V√©rifier le r√©sultat
            if result.returncode == 0:
                # Succ√®s: nettoyer les chunks
                for chunk in chunk_files:
                    chunk.unlink(missing_ok=True)
                return True, f"‚úÖ Audio g√©n√©r√© (en chunks): {voice}"
            elif result.returncode < 0:
                # ffmpeg a √©t√© tu√© (signal), essayer pydub
                print(f"‚ö†Ô∏è  ffmpeg crash detected (signal {-result.returncode}), essai avec pydub...")
                return self._combine_with_pydub(chunk_files, output_file, voice)
            else:
                print(f"‚ö†Ô∏è  ffmpeg error (code {result.returncode}), essai avec pydub...")
                return self._combine_with_pydub(chunk_files, output_file, voice)
        
        except (FileNotFoundError, subprocess.TimeoutExpired) as e:
            # ffmpeg non disponible ou timeout, essayer pydub
            print(f"‚ö†Ô∏è  ffmpeg indisponible ({type(e).__name__}), essai avec pydub...")
            return self._combine_with_pydub(chunk_files, output_file, voice)
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur inattendue ({str(e)}), essai avec pydub...")
            return self._combine_with_pydub(chunk_files, output_file, voice)
    
    def _combine_with_pydub(self, chunk_files, output_file, voice):
        """Combine les chunks avec pydub (alternative √† ffmpeg) ou concat√©nation binaire"""
        try:
            from pydub import AudioSegment
            
            # Combiner tous les chunks
            combined = AudioSegment.empty()
            for i, chunk_file in enumerate(chunk_files):
                print(f"   Ajout chunk {i+1}/{len(chunk_files)}...")
                segment = AudioSegment.from_mp3(str(chunk_file))
                combined += segment
            
            # Exporter le r√©sultat
            combined.export(output_file, format="mp3")
            
            # Nettoyer les chunks
            for chunk in chunk_files:
                chunk.unlink(missing_ok=True)
            
            return True, f"‚úÖ Audio g√©n√©r√© (chunks combin√©s avec pydub): {voice}"
        except (ImportError, ModuleNotFoundError):
            # pydub non disponible, essayer la concat√©nation binaire
            print("‚ö†Ô∏è  pydub non disponible (Python 3.13+), essai de concat√©nation binaire...")
            try:
                # Concat√©nation binaire simple des MP3
                with open(output_file, 'wb') as outfile:
                    for i, chunk_file in enumerate(chunk_files):
                        print(f"   Ajout chunk {i+1}/{len(chunk_files)}...")
                        with open(chunk_file, 'rb') as infile:
                            outfile.write(infile.read())
                
                # Nettoyer les chunks
                for chunk in chunk_files:
                    chunk.unlink(missing_ok=True)
                
                return True, f"‚úÖ Audio g√©n√©r√© (concat√©nation binaire de {len(chunk_files)} chunks): {voice}"
            except Exception as e2:
                print(f"‚ö†Ô∏è  Erreur concat√©nation ({str(e2)}), fallback sur premier chunk")
                return self._fallback_first_chunk(chunk_files, output_file, voice)
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur pydub ({str(e)}), fallback sur premier chunk")
            return self._fallback_first_chunk(chunk_files, output_file, voice)
    
    def _fallback_first_chunk(self, chunk_files, output_file, voice):
        """Fallback: utiliser seulement le premier chunk si ffmpeg √©choue"""
        try:
            chunk_files[0].rename(output_file)
            for chunk in chunk_files[1:]:
                chunk.unlink(missing_ok=True)
            return True, f"‚úÖ Audio g√©n√©r√© (chunk 1 seulement, ffmpeg indisponible): {voice}"
        except Exception as e:
            return False, f"‚ùå Erreur lors du fallback: {str(e)}"

    def generate_dialogue_audio(self, dialogue_segments, output_file, output_format='mp3'):
        """G√©n√®re un fichier audio √† partir de segments de dialogue
        
        Args:
            dialogue_segments: Liste de tuples (locuteur, texte)
            output_file: Chemin du fichier de sortie
            output_format: 'mp3' ou 'wav' (d√©faut: 'mp3')
        
        Note: Azure g√©n√®re directement en MP3 ou WAV selon output_format
        Les segments sont concat√©n√©s en un seul fichier
        Pour les dialogues, --voix sp√©cifique est ignor√© (plusieurs voix n√©cessaires)
        """
        
        # Pour les dialogues, on utilise gender mais on ignore voice_name (plusieurs voix n√©cessaires)
        voice_assigner = DialogueVoiceAssigner(self.langue, self.gender)
        
        # G√©n√©rer un fichier MP3/WAV pour chaque segment
        segment_files = []
        extension = '.mp3' if output_format == 'mp3' else '.wav'
        
        for i, (speaker, text) in enumerate(dialogue_segments):
            # Obtenir une voix pour ce locuteur
            voice = voice_assigner.get_voice_for_speaker(speaker)
            
            # G√©n√©rer l'audio pour cette partie
            segment_file = f"/tmp/segment_{i}_{len(dialogue_segments)}{extension}"
            success, msg = self.generate_audio_from_text(text, segment_file, voice)
            
            if success:
                segment_files.append(segment_file)
            else:
                print(f"  üìç Segment {i}: {msg}")
                return False, f"‚ùå Erreur lors de la g√©n√©ration du segment {i}: {msg}"
        
        # Fusionner les fichiers audio
        if segment_files:
            try:
                import os
                
                # Simple concat√©nation binaire (fonctionne pour MP3 et WAV)
                with open(output_file, 'wb') as outfile:
                    for seg_file in segment_files:
                        with open(seg_file, 'rb') as infile:
                            outfile.write(infile.read())
                
                # Nettoyer les segments temporaires
                for seg_file in segment_files:
                    try:
                        os.remove(seg_file)
                    except:
                        pass
                
                return True, f"‚úÖ Dialogue {output_format.upper()} g√©n√©r√©: {output_file}"
            
            except Exception as e:
                return False, f"‚ùå Erreur: {str(e)}"
        
        return False, "‚ùå Aucun segment g√©n√©r√©"


def main():
    parser = argparse.ArgumentParser(
        description="Convertit un fichier Markdown en MP3 avec Azure TTS",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python md2mp3.py texte.md -l fr
  python md2mp3.py texte.md -l all --voix femme
  python md2mp3.py dialogue.md -l fr (voix al√©atoires pour chaque personnage)
  python md2mp3.py article.md -l us --voix homme
        """
    )

    parser.add_argument(
        "fichier",
        help="Fichier Markdown √† convertir"
    )

    parser.add_argument(
        "-l", "--langue",
        required=True,
        choices=['fr', 'all', 'eng', 'us', 'esp', 'hisp', 'nl', 'co', 'it'],
        help="Langue (fr=fran√ßais, all=allemand, eng=anglais UK, us=anglais US, esp=espagnol, hisp=hispanique, nl=n√©erlandais, co=cor√©en)"
    )

    parser.add_argument(
        "-g", "--genre",
        choices=['femme', 'homme'],
        default=None,
        help="Genre de voix (d√©faut: al√©atoire). Ignor√© si --voix est sp√©cifi√©."
    )

    parser.add_argument(
        "-v", "--voix",
        default=None,
        help="Nom sp√©cifique de voix (ex: 'denise', 'henri', 'aria'). Prioritaire sur --genre. Utilisez --help pour voir toutes les voix disponibles."
    )

    parser.add_argument(
        "--vitesse",
        type=float,
        default=1.0,
        help="Vitesse de lecture de 0.6 (tr√®s ralenti) √† 1.0 (vitesse normale). D√©faut: 1.0"
    )

    parser.add_argument(
        "--format",
        choices=['mp3', 'wav'],
        default='mp3',
        help="Format de sortie (d√©faut: mp3, utiliser wav si ffmpeg ne fonctionne pas)"
    )

    # Option pour activer la conversion Markdown‚ÜíSSML (emphases et pauses)
    parser.add_argument(
        "--ssml",
        action='store_true',
        help="Activer la conversion Markdown‚ÜíSSML: *mot*, **mot**, [p], [p:ms]"
    )

    args = parser.parse_args()

    # Throttle global pour √©viter les 429 si plusieurs appels rapproch√©s
    MIN_GAP = float(os.getenv("MD2MP3_MIN_GAP", "70"))  # secondes entre deux synth√®ses
    THROTTLE_FILE = "/tmp/md2mp3_last_call"
    try:
        last_ts = None
        if os.path.exists(THROTTLE_FILE):
            with open(THROTTLE_FILE, "r") as f:
                last_ts = float(f.read().strip())
        now = time.time()
        if last_ts:
            gap = now - last_ts
            if gap < MIN_GAP:
                wait = MIN_GAP - gap
                print(f"‚è≥ Throttle global: pause {wait:.1f}s pour √©viter 429 (MIN_GAP={MIN_GAP}s)")
                time.sleep(wait)
        # Mettre √† jour le timestamp d√®s le d√©marrage de cette synth√®se
        with open(THROTTLE_FILE, "w") as f:
            f.write(str(time.time()))
    except Exception:
        # En cas d'erreur de throttle, continuer sans bloquer la g√©n√©ration
        pass

    # Valider la vitesse
    if args.vitesse < 0.6 or args.vitesse > 1.0:
        print(f"‚ùå Erreur: La vitesse doit √™tre entre 0.6 et 1.0 (valeur fournie: {args.vitesse})")
        return 1

    # V√©rifier que le fichier existe
    if not os.path.exists(args.fichier):
        print(f"‚ùå Erreur: Fichier '{args.fichier}' non trouv√©")
        return 1

    # Lire le fichier Markdown
    with open(args.fichier, 'r', encoding='utf-8') as f:
        content = f.read()

    # D√©terminer le fichier de sortie
    if args.format == 'wav':
        output_file = args.fichier.replace('.md', '.wav')
    else:
        output_file = args.fichier.replace('.md', '.mp3')

    print(f"üìÑ Lecture: {args.fichier}")
    print(f"üåç Langue: {args.langue}")
    
    # Afficher la voix choisie
    if args.voix:
        print(f"üé§ Voix: {args.voix}")
    elif args.genre:
        print(f"üé§ Genre: {args.genre}")
    else:
        print(f"üé§ Voix: al√©atoire")
    
    print(f"‚è±Ô∏è  Vitesse: {args.vitesse}x" + (" (ralenti)" if args.vitesse < 1.0 else ""))
    print(f"üì¶ Format: {args.format}")
    print()

    try:
        # Nettoyer le texte avec la langue appropri√©e
        cleaned_text = MarkdownCleaner.clean_text(content, args.langue, enable_ssml=args.ssml)
        
        # D√©tecter si c'est un dialogue
        is_dialogue, dialogue_lines = MarkdownCleaner.detect_dialogue(cleaned_text)
        
        if is_dialogue:
            print("üé≠ Dialogue d√©tect√©")
            
            # Parser les lignes de dialogue
            dialogue_segments = []
            for line in dialogue_lines:
                speaker, text = MarkdownCleaner.parse_dialogue_line(line)
                if speaker:
                    dialogue_segments.append((speaker, text))
            
            # G√©n√©rer l'audio du dialogue (Azure TTS uniquement)
            try:
                tts = AzureTTSGenerator(args.langue, args.genre, args.voix, args.vitesse)
                success, msg = tts.generate_dialogue_audio(dialogue_segments, output_file, args.format)
            except Exception as e:
                success = False
                msg = f"‚ùå Azure TTS indisponible: {str(e)}\nüí° V√©rifiez AZURE_SPEECH_KEY et AZURE_SPEECH_REGION dans .env"
        else:
            print("üìñ Texte standard")
            
            # G√©n√©rer l'audio du texte (Azure TTS uniquement)
            try:
                tts = AzureTTSGenerator(args.langue, args.genre, args.voix, args.vitesse)
                success, msg = tts.generate_audio_from_text(cleaned_text, output_file)
            except Exception as e:
                success = False
                msg = f"‚ùå Azure TTS indisponible: {str(e)}\nüí° V√©rifiez AZURE_SPEECH_KEY et AZURE_SPEECH_REGION dans .env"
        
        if success:
            print(msg)
            print(f"‚úÖ Succ√®s: {output_file}")
            return 0
        else:
            print(msg)
            return 1

    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
