#!/usr/bin/env python3
"""
Script pour r√©g√©n√©rer le vocabulaire des docs C2 qui n'en ont pas assez (< 35 mots).
Utilise GPT-4o pour extraire 35 mots de vocabulaire du texte existant.
"""

import os
import re
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

class VocabularyGenerator:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
    def extract_text_from_markdown(self, text_md_content):
        """Extrait le texte principal (sans frontmatter ni vocabulaire existant)"""
        # Supprimer le frontmatter YAML
        if text_md_content.startswith('---'):
            parts = text_md_content.split('---', 2)
            if len(parts) >= 3:
                text_md_content = parts[2]
        
        # Trouver la section "Texte" ou "Text" ou "Texto", etc.
        # Extraire jusqu'√† la section Vocabulaire
        match = re.search(r'##\s+(?:Texte|Text|Texto|Testo|Tekst|ÌÖçÏä§Ìä∏)(.*?)(?:##\s+(?:Vocabulaire|Vocabulary|Vocabulario|Vocabolario|Woordenschat|Ïñ¥Ìúò)|$)', 
                         text_md_content, re.DOTALL | re.IGNORECASE)
        if match:
            return match.group(1).strip()
        return text_md_content
    
    def get_language_from_frontmatter(self, text_md_content):
        """Extrait la langue depuis le frontmatter"""
        match = re.search(r'langue:\s*(.+)', text_md_content)
        if match:
            return match.group(1).strip()
        return "Fran√ßais"  # Default
    
    def get_prompt_from_frontmatter(self, text_md_content):
        """Extrait le prompt depuis le frontmatter"""
        match = re.search(r'prompt:\s*(.+)', text_md_content)
        if match:
            return match.group(1).strip()
        return ""
    
    def generate_vocabulary(self, langue_display, text, prompt):
        """G√©n√®re 35 mots de vocabulaire via GPT-4o"""
        
        # Map langue display ‚Üí langue_code pour d√©terminer format
        langue_map = {
            'Fran√ßais': 'fr',
            'Anglais (UK)': 'eng',
            'Anglais (US)': 'us',
            'Allemand': 'all',
            'Espagnol (Espagne)': 'esp',
            'Espagnol (Am√©rique du Sud)': 'hisp',
            'N√©erlandais': 'nl',
            'Cor√©en': 'cor',
            'Italien': 'it'
        }
        langue_code = langue_map.get(langue_display, 'fr')
        
        # D√©terminer la description et format selon la langue
        lang_descriptions = {
            'fr': ('en fran√ßais', 'article mot_fran√ßais | traduction_n√©erlandaise', 
                   'la maison | huis\nle chat | kat'),
            'all': ('en allemand', 'article mot_allemand | traduction_fran√ßaise',
                   'der Frau | la femme'),
            'eng': ('en anglais', 'mot_anglais | traduction_fran√ßaise',
                   'to see | voir\nhouse | maison'),
            'us': ('en anglais am√©ricain', 'mot_anglais | traduction_fran√ßaise',
                  'to see | voir\nhouse | maison'),
            'esp': ('en espagnol d\'Espagne', 'article mot_espagnol | traduction_fran√ßaise',
                   'la casa | la maison'),
            'hisp': ('en espagnol sud-am√©ricain', 'article mot_espagnol | traduction_fran√ßaise',
                    'la casa | la maison'),
            'nl': ('en n√©erlandais', 'article mot_n√©erlandais | traduction_fran√ßaise',
                  'de hond | le chien'),
            'cor': ('en cor√©en', 'mot_cor√©en ‚Üí romanisation (traduction_fran√ßaise)',
                   'ÍπÄÏπò ‚Üí kimchi (chou ferment√© √©pic√©)'),
            'it': ('en italien', 'article mot_italien | traduction_fran√ßaise',
                  'la casa | la maison')
        }
        
        lang_desc, format_str, example_str = lang_descriptions.get(langue_code, lang_descriptions['fr'])
        
        vocab_prompt = f"""Analyse ce texte {lang_desc} et extrais les 35 mots les plus importants et utiles pour un apprenant.

Pour chaque mot :
- Choisis des mots cl√©s repr√©sentatifs du contenu sur le th√®me "{prompt}"
- Privil√©gie les noms, verbes et adjectifs importants
"""
        
        # Consignes sp√©cifiques par langue
        if langue_code == "all":
            vocab_prompt += "- Pour les noms allemands, INDIQUE TOUJOURS l'article d√©fini (der/die/das) devant le mot\n"
            vocab_prompt += "Format strict (un mot par ligne) :\narticle mot_allemand | traduction_fran√ßaise\n\nExemple:\nder Frau | la femme\n"
        elif langue_code in ["eng", "us"]:
            vocab_prompt += "- Pour les verbes anglais, indique 'to' avant le verbe\n"
            vocab_prompt += "- NE PAS mettre d'article devant les noms anglais\n"
            vocab_prompt += "Format strict (un mot par ligne) :\nmot_anglais | traduction_fran√ßaise\n\nExemple:\nto see | voir\nhouse | maison\n"
        elif langue_code in ["esp", "hisp"]:
            vocab_prompt += "- Pour les noms espagnols, INDIQUE TOUJOURS l'article d√©fini (el/la/los/las) devant le mot\n"
            vocab_prompt += "Format strict (un mot par ligne) :\narticle mot_espagnol | traduction_fran√ßaise\n\nExemple:\nla casa | la maison\nel perro | le chien\n"
        elif langue_code == "nl":
            vocab_prompt += "- Pour les noms n√©erlandais, INDIQUE TOUJOURS l'article d√©fini (de/het) devant le mot\n"
            vocab_prompt += "Format strict (un mot par ligne) :\narticle mot_n√©erlandais | traduction_fran√ßaise\n\nExemple:\nde hond | le chien\nhet huis | la maison\n"
        elif langue_code == "fr":
            vocab_prompt += "- Pour les noms fran√ßais, INDIQUE TOUJOURS l'article d√©fini (le/la/les) devant le mot\n"
            vocab_prompt += "- La TRADUCTION doit √™tre en N√âERLANDAIS (pas en fran√ßais)\n"
            vocab_prompt += "Format strict (un mot par ligne) :\narticle mot_fran√ßais | traduction_n√©erlandaise\n\nExemples:\nla maison | huis\nle chat | kat\n"
        elif langue_code == "cor":
            vocab_prompt += "- Pour chaque mot cor√©en, donne d'abord la romanisation (phon√©tique), puis la traduction en fran√ßais\n"
            vocab_prompt += "Format strict (un mot par ligne) :\nmot_cor√©en ‚Üí romanisation (traduction_fran√ßaise)\n\nExemple:\nÍπÄÏπò ‚Üí kimchi (chou ferment√© √©pic√©)\nÎ∂àÍ≥†Í∏∞ ‚Üí bulgogi (viande marin√©e grill√©e)\n"
        elif langue_code == "it":
            vocab_prompt += "- Pour les noms italiens, INDIQUE TOUJOURS l'article d√©fini (il/la/lo/gli/le) devant le mot\n"
            vocab_prompt += "Format strict (un mot par ligne) :\narticle mot_italien | traduction_fran√ßaise\n\nExemple:\nla casa | la maison\nil gatto | le chat\n"
        else:
            vocab_prompt += "- Pour les noms, INDIQUE l'article d√©fini devant le mot si la langue l'utilise\n"
            vocab_prompt += "Format strict (un mot par ligne) :\nmot_langue | traduction_fran√ßaise\n\nExemple:\nword | traduction\n"

        vocab_prompt += f"\nTEXTE :\n{text}\n\nDonne uniquement la liste des 35 mots au format demand√©, sans num√©rotation, sans commentaire."
        
        print(f"  üìö G√©n√©ration de 35 mots de vocabulaire via GPT-4o...")
        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": vocab_prompt}],
            max_tokens=1024
        )
        
        vocabulary = []
        for line in response.choices[0].message.content.strip().split('\n'):
            separator = '‚Üí' if '‚Üí' in line else '|'
            if separator in line:
                parts = line.split(separator)
                if len(parts) >= 2:
                    word = parts[0].strip().strip('*').strip('-').strip()
                    translation = parts[1].strip().strip('*').strip('-').strip()
                    if word and translation:
                        vocabulary.append((word, translation))
        
        return vocabulary
    
    def update_text_md(self, text_md_path):
        """Met √† jour le fichier text.md avec le nouveau vocabulaire"""
        with open(text_md_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extraire informations
        langue = self.get_language_from_frontmatter(content)
        prompt = self.get_prompt_from_frontmatter(content)
        text = self.extract_text_from_markdown(content)
        
        print(f"  üìñ Langue: {langue}")
        print(f"  üìù Prompt: {prompt}")
        
        # G√©n√©rer vocabulaire
        vocabulary = self.generate_vocabulary(langue, text, prompt)
        
        # Reconstituer le contenu sans la vieille section vocabulaire
        # Supprimer la vieille section vocabulaire
        content = re.sub(
            r'##\s+(?:Vocabulaire|Vocabulary|Vocabulario|Vocabolario|Woordenschat|Ïñ¥Ìúò).*',
            '',
            content,
            flags=re.DOTALL | re.IGNORECASE
        ).rstrip()
        
        # Ajouter la nouvelle section vocabulaire
        content += "\n\n## Vocabulaire\n\n" if langue == "Fran√ßais" else "\n\n## Vocabulary\n\n"
        if langue == "Allemand":
            content += "\n\n## Wortschatz\n\n"
        elif langue in ["Anglais (UK)", "Anglais (US)"]:
            content += "\n\n## Vocabulary\n\n"
        elif langue in ["Espagnol (Espagne)", "Espagnol (Am√©rique du Sud)"]:
            content += "\n\n## Vocabulario\n\n"
        elif langue == "N√©erlandais":
            content += "\n\n## Woordenschat\n\n"
        elif langue == "Cor√©en":
            content += "\n\n## Ïñ¥Ìúò\n\n"
        elif langue == "Italien":
            content += "\n\n## Vocabolario\n\n"
        
        for word, translation in vocabulary:
            content += f"- **{word}** ‚Üí {translation}\n"
        
        # Sauvegarder
        with open(text_md_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"  ‚úÖ {len(vocabulary)} mots de vocabulaire g√©n√©r√©s et sauvegard√©s")
        return len(vocabulary)

def main():
    gen = VocabularyGenerator()
    
    # Trouver les docs C2 avec moins de 35 mots de vocabulaire
    docs_to_fix = []
    for root, dirs, files in os.walk('docs'):
        if 'text.md' in files:
            text_path = os.path.join(root, 'text.md')
            with open(text_path, 'r', encoding='utf-8') as f:
                content = f.read()
                if 'niveau: C2' in content:
                    vocab_count = len(re.findall(r'^- \*\*.+?\*\*', content, re.MULTILINE))
                    if vocab_count < 35:
                        folder_name = os.path.basename(root)
                        docs_to_fix.append((text_path, folder_name, vocab_count))
    
    if not docs_to_fix:
        print("‚úÖ Tous les docs C2 ont 35 mots de vocabulaire ou plus.")
        return
    
    print(f"\nüîß {len(docs_to_fix)} doc(s) C2 √† r√©parer:\n")
    
    for text_path, folder_name, current_vocab in docs_to_fix:
        print(f"üìÅ {folder_name}")
        print(f"  Vocabulaire actuel: {current_vocab}/35")
        
        vocab_count = gen.update_text_md(text_path)
        
        if vocab_count >= 35:
            print(f"  ‚úÖ R√âPAR√â: {vocab_count} mots g√©n√©r√©s\n")
        else:
            print(f"  ‚ö†Ô∏è  ATTENTION: Seulement {vocab_count} mots g√©n√©r√©s (attendu 35)\n")

if __name__ == "__main__":
    main()
